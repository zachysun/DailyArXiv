---
title: Latest 20 Papers - February 19, 2026
labels: documentation
---
## LLM
| **Title** | **Date** | **Cool Paper** | **Comment** |
| --- | --- | --- | --- |
| **[CrispEdit: Low-Curvature Projections for Scalable Non-Destructive LLM Editing](https://arxiv.org/abs/2602.15823v1)** | 2026-02-17 | [Go](https://papers.cool/arxiv/2602.15823v1) |  |
| **[This human study did not involve human subjects: Validating LLM simulations as behavioral evidence](https://arxiv.org/abs/2602.15785v1)** | 2026-02-17 | [Go](https://papers.cool/arxiv/2602.15785v1) |  |
| **[*-PLUIE: Personalisable metric with Llm Used for Improved Evaluation](https://arxiv.org/abs/2602.15778v1)** | 2026-02-17 | [Go](https://papers.cool/arxiv/2602.15778v1) | Under review |
| **[A Differential Fuzzing-Based Evaluation of Functional Equivalence in LLM-Generated Code Refactorings](https://arxiv.org/abs/2602.15761v1)** | 2026-02-17 | [Go](https://papers.cool/arxiv/2602.15761v1) |  |
| **[Under-resourced studies of under-resourced languages: lemmatization and POS-tagging with LLM annotators for historical Armenian, Georgian, Greek and Syriac](https://arxiv.org/abs/2602.15753v1)** | 2026-02-17 | [Go](https://papers.cool/arxiv/2602.15753v1) |  |
| **[FRSICL: LLM-Enabled In-Context Learning Flight Resource Allocation for Fresh Data Collection in UAV-Assisted Wildfire Monitoring](https://arxiv.org/abs/2507.10134v2)** | 2026-02-17 | [Go](https://papers.cool/arxiv/2507.10134v2) |  |
| **[Can Multimodal LLMs Perform Time Series Anomaly Detection?](https://arxiv.org/abs/2502.17812v2)** | 2026-02-17 | [Go](https://papers.cool/arxiv/2502.17812v2) | <details><summary>ACM W...</summary><p>ACM Web Conference 2026 (WWW'26)</p></details> |
| **[A universal LLM Framework for General Query Refinements](https://arxiv.org/abs/2602.15681v1)** | 2026-02-17 | [Go](https://papers.cool/arxiv/2602.15681v1) |  |
| **[LLM-to-Speech: A Synthetic Data Pipeline for Training Dialectal Text-to-Speech Models](https://arxiv.org/abs/2602.15675v1)** | 2026-02-17 | [Go](https://papers.cool/arxiv/2602.15675v1) | <details><summary>8 pag...</summary><p>8 pages, 2 figures, EACL26</p></details> |
| **[Zombie Agents: Persistent Control of Self-Evolving LLM Agents via Self-Reinforcing Injections](https://arxiv.org/abs/2602.15654v1)** | 2026-02-17 | [Go](https://papers.cool/arxiv/2602.15654v1) |  |
| **[Aeon: High-Performance Neuro-Symbolic Memory Management for Long-Horizon LLM Agents](https://arxiv.org/abs/2601.15311v3)** | 2026-02-17 | [Go](https://papers.cool/arxiv/2601.15311v3) | <details><summary>v3: P...</summary><p>v3: Production hardening. Added INT8 quantization (5.6x dot product speedup, 3.1x compression), crash recovery via decoupled WAL (<1% overhead), unlimited text storage via sidecar blob arena with generational GC, and epoch-based reclamation for lock-free reads (P99 750ns under 16-thread contention). Revised for systems engineering clarity</p></details> |
| **[Learning When to Plan: Efficiently Allocating Test-Time Compute for LLM Agents](https://arxiv.org/abs/2509.03581v3)** | 2026-02-17 | [Go](https://papers.cool/arxiv/2509.03581v3) |  |
| **[LLMs Know More About Numbers than They Can Say](https://arxiv.org/abs/2602.07812v2)** | 2026-02-17 | [Go](https://papers.cool/arxiv/2602.07812v2) | <details><summary>EACL ...</summary><p>EACL 2026 (Oral), camera-ready version with GitHub link</p></details> |
| **["What Are You Doing?": Effects of Intermediate Feedback from Agentic LLM In-Car Assistants During Multi-Step Processing](https://arxiv.org/abs/2602.15569v1)** | 2026-02-17 | [Go](https://papers.cool/arxiv/2602.15569v1) | <details><summary>Accep...</summary><p>Accepted (conditionally) at CHI 2026</p></details> |
| **[OpenAIs HealthBench in Action: Evaluating an LLM-Based Medical Assistant on Realistic Clinical Queries](https://arxiv.org/abs/2509.02594v2)** | 2026-02-17 | [Go](https://papers.cool/arxiv/2509.02594v2) | 13 pages, two graphs |
| **[Intermittent Semi-Working Mask: A New Masking Paradigm for LLMs](https://arxiv.org/abs/2408.00539v2)** | 2026-02-17 | [Go](https://papers.cool/arxiv/2408.00539v2) |  |
| **[Your AI Bosses Are Still Prejudiced: The Emergence of Stereotypes in LLM-Based Multi-Agent Systems](https://arxiv.org/abs/2508.19919v2)** | 2026-02-17 | [Go](https://papers.cool/arxiv/2508.19919v2) |  |
| **[Out of the Memory Barrier: A Highly Memory Efficient Training System for LLMs with Million-Token Contexts](https://arxiv.org/abs/2602.02108v3)** | 2026-02-17 | [Go](https://papers.cool/arxiv/2602.02108v3) |  |
| **[LLM-as-Judge on a Budget](https://arxiv.org/abs/2602.15481v1)** | 2026-02-17 | [Go](https://papers.cool/arxiv/2602.15481v1) |  |
| **[In Agents We Trust, but Who Do Agents Trust? Latent Source Preferences Steer LLM Generations](https://arxiv.org/abs/2602.15456v1)** | 2026-02-17 | [Go](https://papers.cool/arxiv/2602.15456v1) | ICLR 2026 |

## Multimodal
| **Title** | **Date** | **Cool Paper** | **Comment** |
| --- | --- | --- | --- |
| **[Understanding vs. Generation: Navigating Optimization Dilemma in Multimodal Models](https://arxiv.org/abs/2602.15772v1)** | 2026-02-17 | [Go](https://papers.cool/arxiv/2602.15772v1) | Accepted to ICLR2026 |
| **[ViTaB-A: Evaluating Multimodal Large Language Models on Visual Table Attribution](https://arxiv.org/abs/2602.15769v1)** | 2026-02-17 | [Go](https://papers.cool/arxiv/2602.15769v1) |  |
| **[ChartEditBench: Evaluating Grounded Multi-Turn Chart Editing in Multimodal Language Models](https://arxiv.org/abs/2602.15758v1)** | 2026-02-17 | [Go](https://papers.cool/arxiv/2602.15758v1) | <details><summary>16 pa...</summary><p>16 pages, 13 figures including Supplementary Material</p></details> |
| **[SSL4EO-S12 v1.1: A Multimodal, Multiseasonal Dataset for Pretraining, Updated](https://arxiv.org/abs/2503.00168v3)** | 2026-02-17 | [Go](https://papers.cool/arxiv/2503.00168v3) |  |
| **[MRC-GAT: A Meta-Relational Copula-Based Graph Attention Network for Interpretable Multimodal Alzheimer's Disease Diagnosis](https://arxiv.org/abs/2602.15740v1)** | 2026-02-17 | [Go](https://papers.cool/arxiv/2602.15740v1) | <details><summary>27 pa...</summary><p>27 pages, 10 figures, 10 table</p></details> |
| **[Can Multimodal LLMs Perform Time Series Anomaly Detection?](https://arxiv.org/abs/2502.17812v2)** | 2026-02-17 | [Go](https://papers.cool/arxiv/2502.17812v2) | <details><summary>ACM W...</summary><p>ACM Web Conference 2026 (WWW'26)</p></details> |
| **[Concept-Enhanced Multimodal RAG: Towards Interpretable and Accurate Radiology Report Generation](https://arxiv.org/abs/2602.15650v1)** | 2026-02-17 | [Go](https://papers.cool/arxiv/2602.15650v1) |  |
| **[Text-Guided Layer Fusion Mitigates Hallucination in Multimodal LLMs](https://arxiv.org/abs/2601.03100v2)** | 2026-02-17 | [Go](https://papers.cool/arxiv/2601.03100v2) |  |
| **[Prompt Reinjection: Alleviating Prompt Forgetting in Multimodal Diffusion Transformers](https://arxiv.org/abs/2602.06886v2)** | 2026-02-17 | [Go](https://papers.cool/arxiv/2602.06886v2) | 18 pages |
| **[How Vision Becomes Language: A Layer-wise Information-Theoretic Analysis of Multimodal Reasoning](https://arxiv.org/abs/2602.15580v1)** | 2026-02-17 | [Go](https://papers.cool/arxiv/2602.15580v1) |  |
| **[Selective Perception for Robot: Task-Aware Attention in Multimodal VLA](https://arxiv.org/abs/2602.15543v1)** | 2026-02-17 | [Go](https://papers.cool/arxiv/2602.15543v1) |  |
| **[Binge Watch: Reproducible Multimodal Benchmarks Datasets for Large-Scale Movie Recommendation on MovieLens-10M and 20M](https://arxiv.org/abs/2602.15505v1)** | 2026-02-17 | [Go](https://papers.cool/arxiv/2602.15505v1) |  |
| **[MMS-VPR: Multimodal Street-Level Visual Place Recognition Dataset and Benchmark](https://arxiv.org/abs/2505.12254v2)** | 2026-02-17 | [Go](https://papers.cool/arxiv/2505.12254v2) | Under review |
| **[Multimodal Peer Review Simulation with Actionable To-Do Recommendations for Community-Aware Manuscript Revisions](https://arxiv.org/abs/2511.10902v2)** | 2026-02-17 | [Go](https://papers.cool/arxiv/2511.10902v2) | <details><summary>Accep...</summary><p>Accepted by TheWebConf 2026 Demo Track</p></details> |
| **[Feasibility-aware Imitation Learning from Observation with Multimodal Feedback](https://arxiv.org/abs/2602.15351v1)** | 2026-02-17 | [Go](https://papers.cool/arxiv/2602.15351v1) |  |
| **[CREMD: Crowd-Sourced Emotional Multimodal Dogs Dataset](https://arxiv.org/abs/2602.15349v1)** | 2026-02-17 | [Go](https://papers.cool/arxiv/2602.15349v1) | Submitted to arXiv |
| **[Effective and Robust Multimodal Medical Image Analysis](https://arxiv.org/abs/2602.15346v1)** | 2026-02-17 | [Go](https://papers.cool/arxiv/2602.15346v1) | <details><summary>Accep...</summary><p>Accepted at Proceedings of the 32nd ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD 2026)</p></details> |
| **[Hierarchical Refinement of Universal Multimodal Attacks on Vision-Language Models](https://arxiv.org/abs/2601.10313v3)** | 2026-02-17 | [Go](https://papers.cool/arxiv/2601.10313v3) | 10 pages, 7 figures |
| **[SIGMUS: Semantic Integration for Knowledge Graphs in Multimodal Urban Spaces](https://arxiv.org/abs/2509.00287v2)** | 2026-02-17 | [Go](https://papers.cool/arxiv/2509.00287v2) | <details><summary>9 pag...</summary><p>9 pages, accepted at UrbComp 2025 KDD 2025</p></details> |
| **[Supporting Multimodal Data Interaction on Refreshable Tactile Displays: An Architecture to Combine Touch and Conversational AI](https://arxiv.org/abs/2602.15280v1)** | 2026-02-17 | [Go](https://papers.cool/arxiv/2602.15280v1) | <details><summary>Paper...</summary><p>Paper to be presented at IEEE PacificVis 2026 (VisNotes)</p></details> |

## AI Agent
| **Title** | **Date** | **Cool Paper** | **Comment** |
| --- | --- | --- | --- |
| **[Hunt Globally: Wide Search AI Agents for Drug Asset Scouting in Investing, Business Development, and Competitive Intelligence](https://arxiv.org/abs/2602.15019v2)** | 2026-02-17 | [Go](https://papers.cool/arxiv/2602.15019v2) |  |
| **[Developing AI Agents with Simulated Data: Why, what, and how?](https://arxiv.org/abs/2602.15816v1)** | 2026-02-17 | [Go](https://papers.cool/arxiv/2602.15816v1) |  |
| **[Your AI Bosses Are Still Prejudiced: The Emergence of Stereotypes in LLM-Based Multi-Agent Systems](https://arxiv.org/abs/2508.19919v2)** | 2026-02-17 | [Go](https://papers.cool/arxiv/2508.19919v2) |  |
| **[A Comparative Analysis of Social Network Topology in Reddit and Moltbook](https://arxiv.org/abs/2602.13920v2)** | 2026-02-17 | [Go](https://papers.cool/arxiv/2602.13920v2) |  |
| **[Visual Persuasion: What Influences Decisions of Vision-Language Models?](https://arxiv.org/abs/2602.15278v1)** | 2026-02-17 | [Go](https://papers.cool/arxiv/2602.15278v1) | 45 pages, 17 figures |
| **[Prover Agent: An Agent-Based Framework for Formal Mathematical Proofs](https://arxiv.org/abs/2506.19923v5)** | 2026-02-17 | [Go](https://papers.cool/arxiv/2506.19923v5) | 49 pages, 4 figures |
| **[Knowing Isn't Understanding: Re-grounding Generative Proactivity with Epistemic and Behavioral Insight](https://arxiv.org/abs/2602.15259v1)** | 2026-02-16 | [Go](https://papers.cool/arxiv/2602.15259v1) |  |
| **[OpenAgentSafety: A Comprehensive Framework for Evaluating Real-World AI Agent Safety](https://arxiv.org/abs/2507.06134v2)** | 2026-02-16 | [Go](https://papers.cool/arxiv/2507.06134v2) | <details><summary>26 pa...</summary><p>26 pages, 10 figures, Accepted at ICLR 2026 and IASEAI 2026</p></details> |
| **[Secure and Energy-Efficient Wireless Agentic AI Networks](https://arxiv.org/abs/2602.15212v1)** | 2026-02-16 | [Go](https://papers.cool/arxiv/2602.15212v1) | Submitted to journal |
| **[Agentic AI for Cybersecurity: A Meta-Cognitive Architecture for Governable Autonomy](https://arxiv.org/abs/2602.11897v2)** | 2026-02-16 | [Go](https://papers.cool/arxiv/2602.11897v2) |  |
| **[ResearchGym: Evaluating Language Model Agents on Real-World AI Research](https://arxiv.org/abs/2602.15112v1)** | 2026-02-16 | [Go](https://papers.cool/arxiv/2602.15112v1) |  |
| **[Sovereign Agents: Towards Infrastructural Sovereignty and Diffused Accountability in Decentralized AI](https://arxiv.org/abs/2602.14951v1)** | 2026-02-16 | [Go](https://papers.cool/arxiv/2602.14951v1) | <details><summary>Submi...</summary><p>Submitted to FAccT 2026</p></details> |
| **[Model Context Protocol (MCP) Tool Descriptions Are Smelly! Towards Improving AI Agent Efficiency with Augmented MCP Tool Descriptions](https://arxiv.org/abs/2602.14878v1)** | 2026-02-16 | [Go](https://papers.cool/arxiv/2602.14878v1) |  |
| **[IntentMiner: Intent Inversion Attack via Tool Call Analysis in the Model Context Protocol](https://arxiv.org/abs/2512.14166v2)** | 2026-02-16 | [Go](https://papers.cool/arxiv/2512.14166v2) | 14 pages, 6 figures |
| **[MATEO: A Multimodal Benchmark for Temporal Reasoning and Planning in LVLMs](https://arxiv.org/abs/2602.14589v1)** | 2026-02-16 | [Go](https://papers.cool/arxiv/2602.14589v1) |  |
| **[When OpenClaw AI Agents Teach Each Other: Peer Learning Patterns in the Moltbook Community](https://arxiv.org/abs/2602.14477v1)** | 2026-02-16 | [Go](https://papers.cool/arxiv/2602.14477v1) | <details><summary>7 pag...</summary><p>7 pages, 1 figure, 3 tables. Submitted to EDM 2026 (Mining track)</p></details> |
| **[A Trajectory-Based Safety Audit of Clawdbot (OpenClaw)](https://arxiv.org/abs/2602.14364v1)** | 2026-02-16 | [Go](https://papers.cool/arxiv/2602.14364v1) |  |
| **[Persuasion Propagation in LLM Agents](https://arxiv.org/abs/2602.00851v2)** | 2026-02-15 | [Go](https://papers.cool/arxiv/2602.00851v2) | <details><summary>Code ...</summary><p>Code available at https://github.com/HyejunJeong/persuasion-propagation</p></details> |
| **[Does Socialization Emerge in AI Agent Society? A Case Study of Moltbook](https://arxiv.org/abs/2602.14299v1)** | 2026-02-15 | [Go](https://papers.cool/arxiv/2602.14299v1) |  |
| **[AgenticSciML: Collaborative Multi-Agent Systems for Emergent Discovery in Scientific Machine Learning](https://arxiv.org/abs/2511.07262v2)** | 2026-02-15 | [Go](https://papers.cool/arxiv/2511.07262v2) |  |

## LLM Inference
| **Title** | **Date** | **Cool Paper** | **Comment** |
| --- | --- | --- | --- |
| **[Learning to Retrieve Navigable Candidates for Efficient Vision-and-Language Navigation](https://arxiv.org/abs/2602.15724v1)** | 2026-02-17 | [Go](https://papers.cool/arxiv/2602.15724v1) |  |
| **[Generalized Parallel Scaling with Interdependent Generations](https://arxiv.org/abs/2510.01143v3)** | 2026-02-16 | [Go](https://papers.cool/arxiv/2510.01143v3) |  |
| **[Nightjar: Dynamic Adaptive Speculative Decoding for Large Language Models Serving](https://arxiv.org/abs/2512.22420v2)** | 2026-02-16 | [Go](https://papers.cool/arxiv/2512.22420v2) | 6 pages, 11 figures |
| **[Efficient Multi-round LLM Inference over Disaggregated Serving](https://arxiv.org/abs/2602.14516v1)** | 2026-02-16 | [Go](https://papers.cool/arxiv/2602.14516v1) |  |
| **[Making Slow Thinking Faster: Compressing LLM Chain-of-Thought via Step Entropy](https://arxiv.org/abs/2508.03346v2)** | 2026-02-16 | [Go](https://papers.cool/arxiv/2508.03346v2) | Accepted by ICLR2026 |
| **[WiSparse: Boosting LLM Inference Efficiency with Weight-Aware Mixed Activation Sparsity](https://arxiv.org/abs/2602.14452v1)** | 2026-02-16 | [Go](https://papers.cool/arxiv/2602.14452v1) |  |
| **[MoESD: Unveil Speculative Decoding's Potential for Accelerating Sparse MoE](https://arxiv.org/abs/2505.19645v4)** | 2026-02-16 | [Go](https://papers.cool/arxiv/2505.19645v4) | <details><summary>Accep...</summary><p>Accepted as spotlight at NeurIPS 2025</p></details> |
| **[HiVid: LLM-Guided Video Saliency For Content-Aware VOD And Live Streaming](https://arxiv.org/abs/2602.14214v1)** | 2026-02-15 | [Go](https://papers.cool/arxiv/2602.14214v1) | ICLR 2026 |
| **[ThunderAgent: A Simple, Fast and Program-Aware Agentic Inference System](https://arxiv.org/abs/2602.13692v1)** | 2026-02-14 | [Go](https://papers.cool/arxiv/2602.13692v1) |  |
| **[ParoQuant: Pairwise Rotation Quantization for Efficient Reasoning LLM Inference](https://arxiv.org/abs/2511.10645v2)** | 2026-02-14 | [Go](https://papers.cool/arxiv/2511.10645v2) | <details><summary>ICLR ...</summary><p>ICLR 2026 | Project page: https://paroquant.z-lab.ai | GitHub: https://github.com/z-lab/paroquant</p></details> |
| **[LO-BCQ: Block Clustered Quantization for 4-bit (W4A4) LLM Inference](https://arxiv.org/abs/2502.05376v2)** | 2026-02-13 | [Go](https://papers.cool/arxiv/2502.05376v2) |  |
| **[Characterize LSM-tree Compaction Performance via On-Device LLM Inference](https://arxiv.org/abs/2602.12669v1)** | 2026-02-13 | [Go](https://papers.cool/arxiv/2602.12669v1) |  |
| **[Unleashing Low-Bit Inference on Ascend NPUs: A Comprehensive Evaluation of HiFloat Formats](https://arxiv.org/abs/2602.12635v1)** | 2026-02-13 | [Go](https://papers.cool/arxiv/2602.12635v1) |  |
| **[TensorCommitments: A Lightweight Verifiable Inference for Language Models](https://arxiv.org/abs/2602.12630v1)** | 2026-02-13 | [Go](https://papers.cool/arxiv/2602.12630v1) | <details><summary>23 pa...</summary><p>23 pages, 8 figures, under review</p></details> |
| **[S-GRec: Personalized Semantic-Aware Generative Recommendation with Asymmetric Advantage](https://arxiv.org/abs/2602.10606v2)** | 2026-02-12 | [Go](https://papers.cool/arxiv/2602.10606v2) |  |
| **[Predicting LLM Output Length via Entropy-Guided Representations](https://arxiv.org/abs/2602.11812v1)** | 2026-02-12 | [Go](https://papers.cool/arxiv/2602.11812v1) |  |
| **[Deep Kernel Fusion for Transformers](https://arxiv.org/abs/2602.11808v1)** | 2026-02-12 | [Go](https://papers.cool/arxiv/2602.11808v1) |  |
| **[GORGO: Maximizing KV-Cache Reuse While Minimizing Network Latency in Cross-Region LLM Load Balancing](https://arxiv.org/abs/2602.11688v1)** | 2026-02-12 | [Go](https://papers.cool/arxiv/2602.11688v1) | <details><summary>12 pa...</summary><p>12 pages, 4 figures. Code: https://github.com/atoniolo76/gotoni/tree/benchmark-load-balancing</p></details> |
| **[Efficient Remote Prefix Fetching with GPU-native Media ASICs](https://arxiv.org/abs/2602.09725v2)** | 2026-02-12 | [Go](https://papers.cool/arxiv/2602.09725v2) |  |
| **[Differentially Private and Communication Efficient Large Language Model Split Inference via Stochastic Quantization and Soft Prompt](https://arxiv.org/abs/2602.11513v1)** | 2026-02-12 | [Go](https://papers.cool/arxiv/2602.11513v1) |  |

## LLM Memory
| **Title** | **Date** | **Cool Paper** | **Comment** |
| --- | --- | --- | --- |
| **[Mnemis: Dual-Route Retrieval on Hierarchical Graphs for Long-Term LLM Memory](https://arxiv.org/abs/2602.15313v1)** | 2026-02-17 | [Go](https://papers.cool/arxiv/2602.15313v1) | 10 pages |
| **[ShardMemo: Masked MoE Routing for Sharded Agentic LLM Memory](https://arxiv.org/abs/2601.21545v1)** | 2026-01-29 | [Go](https://papers.cool/arxiv/2601.21545v1) |  |
| **[Are LLMs Really Not Knowledgeable? Mining the Submerged Knowledge in LLMs' Memory](https://arxiv.org/abs/2412.20846v2)** | 2026-01-28 | [Go](https://papers.cool/arxiv/2412.20846v2) |  |
| **[GLOVE: Global Verifier for LLM Memory-Environment Realignment](https://arxiv.org/abs/2601.19249v1)** | 2026-01-27 | [Go](https://papers.cool/arxiv/2601.19249v1) |  |
| **[MemoryRewardBench: Benchmarking Reward Models for Long-Term Memory Management in Large Language Models](https://arxiv.org/abs/2601.11969v2)** | 2026-01-24 | [Go](https://papers.cool/arxiv/2601.11969v2) |  |
| **[Generating Literature-Driven Scientific Theories at Scale](https://arxiv.org/abs/2601.16282v1)** | 2026-01-22 | [Go](https://papers.cool/arxiv/2601.16282v1) | <details><summary>9 pag...</summary><p>9 pages plus appendix, 3 figures</p></details> |
| **[Memory in the Age of AI Agents](https://arxiv.org/abs/2512.13564v2)** | 2026-01-13 | [Go](https://papers.cool/arxiv/2512.13564v2) |  |
| **[Memory Bear AI A Breakthrough from Memory to Cognition Toward Artificial General Intelligence](https://arxiv.org/abs/2512.20651v1)** | 2025-12-17 | [Go](https://papers.cool/arxiv/2512.20651v1) |  |
| **[Beyond Task Completion: An Assessment Framework for Evaluating Agentic AI Systems](https://arxiv.org/abs/2512.12791v2)** | 2025-12-16 | [Go](https://papers.cool/arxiv/2512.12791v2) |  |
| **[Large-Language Memorization During the Classification of United States Supreme Court Cases](https://arxiv.org/abs/2512.13654v1)** | 2025-12-15 | [Go](https://papers.cool/arxiv/2512.13654v1) | <details><summary>7 pag...</summary><p>7 pages, 1 figure, Appendix of Prompts</p></details> |
| **[MemoryBench: A Benchmark for Memory and Continual Learning in LLM Systems](https://arxiv.org/abs/2510.17281v4)** | 2025-12-12 | [Go](https://papers.cool/arxiv/2510.17281v4) |  |
| **[A Monad-Based Clause Architecture for Artificial Age Score (AAS) in Large Language Models](https://arxiv.org/abs/2512.11835v1)** | 2025-12-03 | [Go](https://papers.cool/arxiv/2512.11835v1) | <details><summary>42 pa...</summary><p>42 pages, 6 toy simulation Python implementations, 20 monad clauses instantiated across six system bundles (ontology, dynamics, representation and consciousness, harmony and reason, body and organisation, teleology)</p></details> |
| **[Mnemosyne: An Unsupervised, Human-Inspired Long-Term Memory Architecture for Edge-Based LLMs](https://arxiv.org/abs/2510.08601v1)** | 2025-10-07 | [Go](https://papers.cool/arxiv/2510.08601v1) | 12 pages, 4 figures |
| **[ArcMemo: Abstract Reasoning Composition with Lifelong LLM Memory](https://arxiv.org/abs/2509.04439v3)** | 2025-10-04 | [Go](https://papers.cool/arxiv/2509.04439v3) |  |
| **[A-MemGuard: A Proactive Defense Framework for LLM-Based Agent Memory](https://arxiv.org/abs/2510.02373v1)** | 2025-09-29 | [Go](https://papers.cool/arxiv/2510.02373v1) |  |
| **[Memory in Large Language Models: Mechanisms, Evaluation and Evolution](https://arxiv.org/abs/2509.18868v1)** | 2025-09-23 | [Go](https://papers.cool/arxiv/2509.18868v1) | <details><summary>50 pa...</summary><p>50 pages, 1 figure, 8 tables This is a survey/framework paper on LLM memory mechanisms and evaluation</p></details> |
| **[Understanding Users' Privacy Perceptions Towards LLM's RAG-based Memory](https://arxiv.org/abs/2508.07664v1)** | 2025-08-11 | [Go](https://papers.cool/arxiv/2508.07664v1) |  |
| **[Editing as Unlearning: Are Knowledge Editing Methods Strong Baselines for Large Language Model Unlearning?](https://arxiv.org/abs/2505.19855v1)** | 2025-05-26 | [Go](https://papers.cool/arxiv/2505.19855v1) | Preprint |
| **[UserCentrix: An Agentic Memory-augmented AI Framework for Smart Spaces](https://arxiv.org/abs/2505.00472v1)** | 2025-05-01 | [Go](https://papers.cool/arxiv/2505.00472v1) |  |
| **[Cognitive Memory in Large Language Models](https://arxiv.org/abs/2504.02441v2)** | 2025-04-24 | [Go](https://papers.cool/arxiv/2504.02441v2) | 37 pages, 9 figures |

